---
created: 2024-10-10T10:32:48 (UTC +01:00)
tags: []
source: https://console.groq.com/docs/rate-limits
author: 
---

# GroqCloud

> ## Excerpt
> Experience the fastest inference in the world

---
## Supported Models

GroqCloud currently supports the following models:

### [Distil-Whisper English](https://console.groq.com/docs/rate-limits#distilwhisper-english)

-   **Model ID:** `distil-whisper-large-v3-en`
-   **Developer:** HuggingFace
-   **Max File Size:** 25 MB
-   [Model Card](https://huggingface.co/distil-whisper/distil-large-v3)

### [Gemma 2 9B](https://console.groq.com/docs/rate-limits#gemma-2-9b)

-   **Model ID:** `gemma2-9b-it`
-   **Developer:** Google
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/google/gemma-2-9b-it)

### [Gemma 7B](https://console.groq.com/docs/rate-limits#gemma-7b)

-   **Model ID:** `gemma-7b-it`
-   **Developer:** Google
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/google/gemma-1.1-7b-it)

### [Llama 3 Groq 70B Tool Use (Preview)](https://console.groq.com/docs/rate-limits#llama-3-groq-70b-tool-use-preview)

-   **Model ID:** `llama3-groq-70b-8192-tool-use-preview`
-   **Developer:** Groq
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use)

### [Llama 3 Groq 8B Tool Use (Preview)](https://console.groq.com/docs/rate-limits#llama-3-groq-8b-tool-use-preview)

-   **Model ID:** `llama3-groq-8b-8192-tool-use-preview`
-   **Developer:** Groq
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/Groq/Llama-3-Groq-8B-Tool-Use)

### [Llama 3.1 405B](https://console.groq.com/docs/rate-limits#llama-31-405b)

-   Offline due to overwhelming demand! Stay tuned for updates.

### [Llama 3.1 70B](https://console.groq.com/docs/rate-limits#llama-31-70b)

-   **Model ID:** `llama-3.1-70b-versatile`
-   **Developer:** Meta
-   **Context Window:** 128k tokens (`max_tokens` limited to 8k)
-   [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)

### [Llama 3.1 8B](https://console.groq.com/docs/rate-limits#llama-31-8b)

-   **Model ID:** `llama-3.1-8b-instant`
-   **Developer:** Meta
-   **Context Window:** 128k tokens (`max_tokens` limited to 8k)
-   [Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)

### [Llama 3.2 1B (Preview)](https://console.groq.com/docs/rate-limits#llama-32-1b-preview)

-   **Model ID:** `llama-3.2-1b-preview`
-   **Developer:** Meta
-   **Context Window:** 128k tokens (temporarily limited to 8k in preview)
-   [Model Card](https://huggingface.co/meta-llama/Llama-3.2-1B)

### [Llama 3.2 3B (Preview)](https://console.groq.com/docs/rate-limits#llama-32-3b-preview)

-   **Model ID:** `llama-3.2-3b-preview`
-   **Developer:** Meta
-   **Context Window:** 128k tokens (temporarily limited to 8k in preview)
-   [Model Card](https://huggingface.co/meta-llama/Llama-3.2-3B)

### [Llama 3.2 11B Vision (Preview)](https://console.groq.com/docs/rate-limits#llama-32-11b-vision-preview)

-   **Model ID:** `llama-3.2-11b-vision-preview`
-   **Developer:** Meta
-   **Context Window:** 128k tokens (temporarily limited to 8k in preview)
-   [Model Card](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision)

### [Llama 3.2 90B (Preview) **Coming Soon**](https://console.groq.com/docs/rate-limits#llama-32-90b-preview-object-object)

-   **Model ID:** `llama-3.2-90b-vision-preview`
-   **Developer:** Meta
-   **Context Window:** 128k tokens (temporarily limited to 8k in preview)
-   [Model Card](https://huggingface.co/meta-llama/Llama-3.2-90B-Vision)

### [Llama Guard 3 8B](https://console.groq.com/docs/rate-limits#llama-guard-3-8b)

-   **Model ID:** `llama-guard-3-8b`
-   **Developer:** Meta
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/meta-llama/Llama-Guard-3-8B)

### [LLaVA 1.5 7B](https://console.groq.com/docs/rate-limits#llava-15-7b)

-   **Model ID:** `llava-v1.5-7b-4096-preview`
-   **Developer:** Haotian Liu
-   **Context Window:** 4,096 tokens
-   [Model Card](https://huggingface.co/liuhaotian/llava-v1.5-7b)

### [Meta Llama 3 70B](https://console.groq.com/docs/rate-limits#meta-llama-3-70b)

-   **Model ID:** `llama3-70b-8192`
-   **Developer:** Meta
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct)

### [Meta Llama 3 8B](https://console.groq.com/docs/rate-limits#meta-llama-3-8b)

-   **Model ID:** `llama3-8b-8192`
-   **Developer:** Meta
-   **Context Window:** 8,192 tokens
-   [Model Card](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)

### [Mixtral 8x7B](https://console.groq.com/docs/rate-limits#mixtral-8x7b)

-   **Model ID:** `mixtral-8x7b-32768`
-   **Developer:** Mistral
-   **Context Window:** 32,768 tokens
-   [Model Card](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)

### [Whisper Large V3](https://console.groq.com/docs/rate-limits#whisper-large-v3)

-   **Model ID:** `whisper-large-v3`
-   **Developer:** OpenAI
-   **File Size:** 25 MB
-   [Model Card](https://huggingface.co/openai/whisper-large-v3)

### [Whisper Large V3 Turbo](https://console.groq.com/docs/rate-limits#whisper-large-v3-turbo)

-   **Model ID:** `whisper-large-v3-turbo`
-   **Developer:** OpenAI
-   **File Size:** 25 MB
-   [Model Card](https://huggingface.co/openai/whisper-large-v3-turbo)

These are chat and audio type models and are directly accessible through the GroqCloud Models API endpoint using the model IDs mentioned above. You can use the `https://api.groq.com/openai/v1/models` endpoint to return a JSON list of all active models:

  

  

```py
1import requests 2import os 3 4api_key = os.environ.get("GROQ_API_KEY") 5url = "https://api.groq.com/openai/v1/models" 6 7headers = { 8 "Authorization": f"Bearer {api_key}", 9 "Content-Type": "application/json" 10} 11 12response = requests.get(url, headers=headers) 13 14print(response.json())
```
